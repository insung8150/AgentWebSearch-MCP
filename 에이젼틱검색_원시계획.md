# 에이전틱 검색 - 원래 목표

## 에이전틱 검색 실제 흐름

```
1. 사용자 질문 입력
    ↓
2. AgentCPM-Explore가 검색 플랜 생성
   (예: "LM Studio 최신 버전" → ["LM Studio release 2026", "LM Studio changelog", "LM Studio github"])
    ↓
3. 여러 검색어를 병렬로 검색 엔진에 요청 ← 병렬화 필요한 이유
    ↓
4. 모든 결과 수집
    ↓
5. AgentCPM-Explore가 종합해서 최종 응답
```

### 핵심
- **에이전틱** = LLM이 스스로 계획 → 실행 → 종합
- 플랜에서 여러 검색어가 나옴 → **병렬 검색 필수**
- 순차로 하면 타임아웃

---

## 전체 맥락

```
AgentCPM-Explore 구현 중 (메인 프로젝트)
    ↓
검색 시 타임아웃 발생 (순차 요청 문제)
    ↓
병렬화를 따로 분리해서 테스트 (smartcrawl-mcp) ← 지금 여기
    ↓
테스트 완료 후 AgentCPM-Explore에 적용
```

- **메인 프로젝트**: AgentCPM-Explore 구현
- **서브 문제**: 검색 병렬화 (따로 분리해서 테스트)
- **부수 효과**: claude_lmstudio도 혜택

---

## 문제

| 항목 | 내용 |
|------|------|
| **증상** | 로컬 LLM 검색 시 30초+ 타임아웃 |
| **원인** | MCP가 네이버/구글에 순차 요청 |
| **해결** | `Promise.allSettled()`로 병렬 요청 |
| **결과** | 20초 → 10초 단축 |

---

## 왜 MCP가 필요한가?

| 실행 방식 | WebSearch (내장) | MCP |
|----------|------------------|-----|
| `claude` (API) | ✅ 사용 가능 | 선택 |
| `claude_lmstudio` (로컬) | ❌ 사용 불가 | **필수** |

- Claude API는 WebSearch 내장 도구 있음
- 로컬 LLM은 없음 → SmartCrawl MCP에 의존 → 병렬화 필요

---

## 구조

```
Claude Code (로컬 LLM)
    ↓
smartcrawl-mcp (MCP) ← 병렬화 구현
    ↓
smartCrawl_server (Express, port 33002)
    ↓
네이버/구글 크롤링
```

| 구성요소 | 위치 |
|----------|------|
| smartCrawl_server | `~/JOB_FOLD/Money_total/smartCrawl_server` |
| smartcrawl-mcp | `~/beads_for_claude/smartcrawl-mcp` |

---

## claude_lmstudio란?

- Claude Code를 **로컬 LLM**으로 실행하는 래퍼
- 위치: `/usr/local/bin/claude_lmstudio`
- 백엔드: LM Studio (port 1234)
- 무료, 도구 사용 가능 (LM Studio 0.4+ Anthropic API 호환)

---

## 현재 상태

**완료됨** - `smartcrawl-mcp/src/index.ts`에 병렬화 구현됨

---

## 진행 결과 (2026-02-15)

- 기존 smartCrawl_server는 **수정하지 않고** 동일 구조를 복사하여 별도 서버 생성.
- 위치: `~/JOB_FOLD/LLM_test/Agent_CPM_Explore/AgentCPM/AgentCPM-Explore/smartCrawl_server_agentcpm`
- 포트: **33003** (기존 33002와 분리)
- 구글 검색 페이지는 CAPTCHA 문제로 기본 selenium 경로가 막혔음.
  - **엔진 폴백(Playwright → Axios → Puppeteer → Selenium)** 적용하여 우회 성공.
- 새 서버에서 `portal=google` 및 `portal=both` 검색 테스트 **정상 동작 확인**.
- 대응 MCP도 별도 복사 생성:
  - `~/JOB_FOLD/LLM_test/Agent_CPM_Explore/AgentCPM/AgentCPM-Explore/smartcrawl-mcp-agentcpm`
  - smartcrawl URL을 **33003**으로 연결.
- 결론: **AgentCPM-Explore용 검색 경로 분리 구성 완료, 구글/네이버 모두 성공**.

---

## 진행 결과 (2026-02-15, Brave 포함)

- **기존 smartCrawl_server 수정 없이** 복사본으로 별도 서버 구성.
- 새 서버 위치: `~/JOB_FOLD/LLM_test/Agent_CPM_Explore/AgentCPM/AgentCPM-Explore/smartCrawl_server_agentcpm`
- 포트: **33003** (기존 33002와 완전 분리)

### 변경 사항 (복사본만)
- **Google 검색 엔진 폴백 적용**: Playwright → Axios → Puppeteer → Selenium
  - CAPTCHA 차단 시 자동 우회
- **Brave 검색 포털 추가**
  - `portal=brave` 지원
  - `portal=all` = naver + google + brave
- MCP 복사본도 Brave/all 지원:
  - `~/JOB_FOLD/LLM_test/Agent_CPM_Explore/AgentCPM/AgentCPM-Explore/smartcrawl-mcp-agentcpm`
  - smartcrawl URL: `http://localhost:33003`

### 테스트 결과
- `portal=google` → **정상 (5건)**
- `portal=brave` → **정상 (3건)**
- `portal=all` → **정상 (9건 = naver+google+brave)**

### AgentCPM-Explore 연동
- `search_agent.py`가 **33003 + portal=all** 사용하도록 변경됨.
- 결과: 네이버/구글/브레이브 모두 병렬 수집 가능 → 검색 풍부도 상승.

✅ 결론: **기존 서비스 영향 없이** AgentCPM-Explore 전용 검색 경로 확장 완료.

---

## 진행 결과 (2026-02-16, E2E 재검증)

- AgentCPM-Explore 검색 에이전트에 **쿼리 상한(3개)** 적용하여 E2E 타임아웃 문제 해결.
  - `search_agent.py`에서 `MAX_SEARCH_QUERIES = 3` 적용
  - 모델이 많은 쿼리를 생성해도 실제 실행은 3개로 제한됨
- E2E 테스트 정상 완료:
  - 실행: `search_agent.py "gpt-5.3에 대해 최신 정보를 찾아 요약해줘"`
  - 결과: GPT‑5.3‑Codex(2026‑02‑05) / Codex‑Spark(2026‑02‑12) 포함 요약 정상 출력
- 결론: **모든 포털(all) 기반 검색 + E2E 응답 생성까지 안정화 완료**.

---

## 진행 결과 (2026-02-16, 공식 fetch + 출처 + 로그 저장)

- `search_agent.py`에 **공식 URL 강제 fetch_url** 로직 추가.
  - 검색 결과에서 공식 도메인(OpenAI/GitHub 등) 발견 시 자동으로 `fetch_url` 실행.
  - 공식 페이지 내용이 반드시 포함되도록 강제.
- **최종 답변에 출처(URL) 목록 자동 첨부** 기능 추가.
- **E2E 로그 파일 저장** 기능 추가:
  - 저장 위치: `AgentCPM-Explore/outputs/search_agent_logs/`
  - 형식: `search_agent_log_YYYYMMDD_HHMMSS.json`

### E2E 테스트 결과
- 실행: `search_agent.py "gpt-5.3에 대해 최신 정보를 찾아 요약해줘"`
- 공식 페이지 fetch_url 실행 확인 (openai.com)
- 최종 답변에 출처(URL) 포함 확인
- 로그 파일 생성 확인:
  - 예시: `search_agent_log_20260216_002902.json`

✅ 결론: **공식 페이지 강제 읽기 + 출처 포함 + 로그 저장까지 적용 및 E2E 검증 완료**.



• 공식 페이지 강제 fetch_url + 출처(URL) 첨부 + E2E 로그 저장을 search_agent.py에 반영했고, GPT‑5.3 쿼리로 E2E 테스트까지 완
  료했어. 최종 응답에 출처가 붙고 로그 파일이 생성되는 것 확인했어.

  - 변경 파일: Agent_CPM_Explore/AgentCPM/AgentCPM-Explore/search_agent.py
  - 계획서 업데이트: /home/yooha/JOB_FOLD/LLM_test/Kimi_K2-5/에이젼틱검색_원시계획.md
  - E2E 실행: python3 .../search_agent.py "gpt-5.3에 대해 최신 정보를 찾아 요약해줘"
  - 확인 결과:
      - 공식 URL 발견 시 강제 fetch_url 실행됨
      - 최종 답변에 출처(URL) 목록 자동 추가됨
      - 로그 파일 생성됨: Agent_CPM_Explore/AgentCPM/AgentCPM-Explore/outputs/search_agent_logs/
        search_agent_log_20260216_002902.json

  원하면 다음 중 진행할 수 있어:

  1. 공식 도메인 목록(OFFICIAL_DOMAINS) 추가/조정
  2. 다른 키워드로 E2E 추가 검증
  
  
  
                                                                                                                              
● 분리 완료                                                                                                                  
                                                                                                                             
  새 구조                                                                                                                    
                                                                                                                             
  /home/yooha/JOB_FOLD/LLM_test/                                                                                             
  ├── Agent_search/                    ← 새로 분리 (에이전틱 검색)                                                           
  │   ├── search_agent.py                                                                                                    
  │   ├── start_sglang.sh                                                                                                    
  │   ├── smartCrawl_server/           (port 33003)                                                                          
  │   ├── smartcrawl-mcp/                                                                                                    
  │   ├── google_search_test/                                                                                                
  │   ├── outputs/                                                                                                           
  │   ├── venv/                                                                                                              
  │   ├── README.md                                                                                                          
  │   └── 에이젼틱검색_원시계획.md                                                                                           
  │                                                                                                                          
  └── Agent_CPM_Explore/AgentCPM/AgentCPM-Explore/   ← 원본 유지 (모델 학습용)                                               
      ├── AgentDock/                                                                                                         
      ├── AgentRL/                                                                                                           
      ├── AgentToLeaP/                                                                                                       
      ├── sft/                                                                                                               
      ├── src/                                                                                                               
      └── quickstart.py                                                                                                      
                                                                                                                             
  상태                                                                                                                       
  ┌─────────────────────────┬────────────────────────┐                                                                       
  │          항목           │          상태          │                                                                       
  ├─────────────────────────┼────────────────────────┤                                                                       
  │ Agent_search 폴더 생성  │ ✅                     │                                                                       
  ├─────────────────────────┼────────────────────────┤                                                                       
  │ 파일 이동               │ ✅                     │                                                                       
  ├─────────────────────────┼────────────────────────┤                                                                       
  │ venv 생성               │ ✅                     │                                                                       
  ├─────────────────────────┼────────────────────────┤                                                                       
  │ README.md 작성          │ ✅                     │                                                                       
  ├─────────────────────────┼────────────────────────┤                                                                       
  │ 원본 폴더 정리          │ ✅                     │                                                                       
  ├─────────────────────────┼────────────────────────┤                                                                       
  │ smartCrawl 서버 (33003) │ ✅ 실행 중             │                                                                       
  ├─────────────────────────┼────────────────────────┤                                                                       
  │ E2E 테스트              │ ✅ 3턴 진행 (타임아웃) │                                                                       
  └─────────────────────────┴────────────────────────┘                                                                       
  완전 분리 완료. 모델 학습용(AgentCPM-Explore)과 검색용(Agent_search)이 분리되었습니다.

---

## 진행 결과 (2026-02-16, 한글 쿼리 전처리 추가)

### 문제
- **한글 외래어** 쿼리 ("맥5 울트라") → AgentCPM-Explore(4B)가 키워드 인식 실패
- **영어 키워드** 포함 시 ("Apple M5 Ultra") → 정상 동작

### 해결: 규칙 기반 전처리 추가
- LLM 전처리 시도 → 4B 모델이 JSON 생성도 실패
- **규칙 기반으로 전환**: 외래어 사전 + 숫자 패턴 매칭

### 구현 (`search_agent.py`)

```python
# 외래어 → 영어 번역 사전
FOREIGN_WORD_MAP = {
    "맥": "Mac", "맥북": "MacBook", "아이폰": "iPhone",
    "울트라": "Ultra", "프로": "Pro", "맥스": "Max",
    "테슬라": "Tesla", "엔비디아": "NVIDIA", "구글": "Google",
    "챗지피티": "ChatGPT", "지피티": "GPT", ...
}

# 숫자 패턴 (맥5 → M5)
NUMBER_PATTERN = re.compile(r'맥(\d+)')
```

### 전처리 동작 예시

| 입력 | 타입 | 출력 |
|------|------|------|
| "맥5 울트라 최신 정보" | foreign | `['M5 Ultra', 'M5 Ultra latest', 'M5 Ultra 2026']` |
| "삼성전자 실적 2026" | korean | `['삼성전자 실적 2026']` (그대로) |
| "테슬라 주가" | foreign | `['Tesla']` |

### 테스트 결과

| 테스트 케이스 | 전처리 | 검색 | 최종 답변 |
|--------------|--------|------|----------|
| "맥5 울트라" (외래어) | M5 Ultra 변환 ✅ | 2턴 ✅ | M5 Ultra 정보 ✅ |
| "삼성전자 실적 2026" (순수 한글) | 그대로 ✅ | 8턴 ✅ | 매출/영업이익 상세 ✅ |

### 핵심 로직

```
사용자 쿼리
    ↓
preprocess_query_sync() ← 규칙 기반 (LLM 불필요, 빠름)
    ↓
외래어 감지?
    ├─ Yes → 영어 쿼리 힌트 추가 [HINT: ...]
    └─ No  → 원본 그대로 사용
    ↓
AgentCPM-Explore 모델 호출
    ↓
검색 실행
```

✅ 결론: **한글 외래어 자동 변환 + 순수 한글 보존** 완료.

---

## 진행 결과 (2026-02-16, 엔진 캐시 + fallback 순서 최적화)

### 문제
- **puppeteer fallback이 너무 느림** (~13초)
- 검색 시 axios 차단 → puppeteer로 fallback → 전체 검색 시간 지연
- 서버 재시작 시 캐시 초기화 → 첫 요청도 느림

### 해결 1: Fallback 순서 변경

**변경 전**: axios → puppeteer → playwright → selenium
**변경 후**: axios → playwright → selenium → puppeteer

| 순서 | 엔진 | 특징 |
|------|------|------|
| 1 | axios | 가장 빠름 (~0.5초) |
| 2 | playwright | 안정적 (~3-5초) |
| 3 | selenium | 범용 |
| 4 | puppeteer | 가장 느림 (~13초), 최후의 수단 |

**수정 파일**:
- `smartCrawl_server/src/core/smartCrawl.ts` - smartCrawl() 함수
- `smartCrawl_server/src/server.ts` - GOOGLE_ENGINE_FALLBACK

### 해결 2: 파일 기반 엔진 캐시

**캐시 파일**: `smartCrawl_server/engine_cache.json`

```json
{
  "naver": "axios",
  "google": "playwright",
  "brave": "axios",
  "updated_at": "2026-02-15T17:08:06.750Z"
}
```

**동작 방식**:
| 시점 | 동작 |
|------|------|
| 서버 시작 | `engine_cache.json` 로드 → 캐시된 엔진 먼저 시도 |
| 검색 성공 | 사용한 엔진 캐시 + 파일 저장 |
| 서버 재시작 | 파일에서 로드 → 첫 요청도 빠름 |

### 해결 3: Brave 캐시 추가

- 기존: naver, google만 캐시
- 변경: **naver, google, brave** 3개 포털 모두 캐시
- brave도 smartCrawl fallback 사용하도록 변경

### 캐시 상태 확인 API

```bash
curl http://localhost:33003/cache
# {"naver":"axios","google":"playwright","brave":"axios",...}
```

### 효과

| 항목 | 개선 전 | 개선 후 |
|------|--------|--------|
| Google 첫 요청 | ~13초 (puppeteer) | ~3초 (playwright) |
| 서버 재시작 후 | 캐시 초기화 | 파일에서 로드 |
| Brave 캐시 | 없음 | 지원 |

✅ 결론: **puppeteer 맨 뒤로 + 파일 캐시 + 3개 포털 캐시 지원** 완료.

---

## 진행 결과 (2026-02-16, 본문 크롤링 병렬화)

### 문제
- 검색 페이지는 빠름 (1~6초)
- **본문 크롤링이 순차 실행** → all 검색 시 38초+

### 원인: 순차 for 루프

```javascript
// 변경 전 (순차)
for (const item of resultsToProcess) {
  const articleResult = await smartCrawl(item.url);  // 순차 대기
}
```

### 해결: Promise.all 병렬화

```javascript
// 변경 후 (병렬)
const crawlPromises = resultsToProcess.map(async (item) => {
  const articleResult = await smartCrawl(item.url);
  // ...
});
const crawlResults = await Promise.all(crawlPromises);
```

### 수정 파일
- `smartCrawl_server/src/server.ts`
  - naver 본문 크롤링 병렬화
  - google 본문 크롤링 병렬화
  - brave 본문 크롤링 병렬화

### 테스트 결과

| 테스트 | 소요 시간 | 비고 |
|--------|----------|------|
| naver "AI" | **0.5초** | axios 성공 |
| google "AI" | **0.8초** | axios 성공 |
| brave "test" | **1.9초** | axios 성공 |
| all "typescript" | **3.8초** | 병렬화 효과 확인 |
| all "AI" | 38초 | openai.com → selenium fallback (병목) |

### 순차 vs 병렬 비교

| 방식 | 3개 URL (2초, 2초, 30초) | 결과 |
|------|--------------------------|------|
| 순차 | 2 + 2 + 30 | 34초 |
| **병렬** | max(2, 2, 30) | **30초** |

### 결론

- **병렬화 작동 확인**: 대부분 3-4초로 단축
- **병목 원인**: 특정 URL이 selenium fallback 필요 시 그 URL이 전체 시간 결정
- 순차였으면 더 오래 걸렸을 것 → **병렬화 효과 확실**

✅ 결론: **naver/google/brave 본문 크롤링 병렬화** 완료.

---

## 진행 결과 (2026-02-16, 타임아웃 5초 최적화)

### 문제
- selenium fallback 시 **30초 타임아웃** → 전체 검색 지연
- openai.com 등 특정 사이트에서 fallback 연쇄로 시간 소요

### 해결: 타임아웃 5초로 단축

**근거**: 대부분의 성공 요청은 2-3초 내 완료. 5초 초과 시 fallback보다 스킵이 효율적.

### 수정 파일

1. `smartCrawl_server/src/types/engine.ts`
   ```typescript
   timeout: parseInt(process.env.CRAWLER_TIMEOUT || '5000', 10),  // 30초 → 5초
   ```

2. `smartCrawl_server/src/engines/playwright.ts`
   ```typescript
   // 독자적 DEFAULT_TIMEOUT 제거 → DEFAULT_ENGINE_CONFIG.timeout 사용
   page.setDefaultTimeout(DEFAULT_ENGINE_CONFIG.timeout);
   ```

### 테스트 결과 (5초 타임아웃)

| 포털 | 이전 | 현재 | 개선율 |
|------|------|------|--------|
| naver | 1.46초 | **0.71초** | 51% |
| google | 6.02초 | **0.91초** | 85% |
| brave | 36초 | **4.87초** | 86% |
| **all** | 38.28초 | **12.72초** | **67%** |

### 핵심 원리

- 30초 fallback 대기 → 5초로 빠르게 실패 처리
- 느린 사이트는 5초 내 실패 → 다음 엔진으로 빠르게 전환
- 대부분 2-3초 성공 → 5초 충분

✅ 결론: **타임아웃 5초 최적화로 전체 검색 67% 단축** 완료.

---

## 진행 결과 (2026-02-16, 전체 병렬 크롤링 구조 개선)

### 문제
- 각 포털 내에서는 병렬이지만, **포털 간 순차 처리**
- naver 크롤링 완료 → google → brave (가장 느린 것 기다려야 함)

### 해결: 2단계 구조로 리팩토링

```
[1단계] URL 수집 (모든 포털 병렬)
   naver ─┬─→ URL 3개
   google ─┼─→ URL 3개  → 총 9개 URL
   brave ─┴─→ URL 3개

[2단계] 모든 URL 한꺼번에 병렬 크롤링 + 개별 타임아웃
   9개 URL 동시 시작 → 5초 타임아웃 → 완료된 것만 반환
```

### 핵심 변경

1. **URL 수집 단계 분리** (`collectNaverUrls`, `collectGoogleUrls`, `collectBraveUrls`)
   - 검색 페이지 크롤링 → URL 추출만
   - 본문 크롤링 X

2. **통합 크롤링 함수** (`crawlWithTimeout`)
   ```typescript
   const CRAWL_TIMEOUT_MS = 5000;

   const crawlWithTimeout = async (item: UrlItem): Promise<any> => {
     return Promise.race([
       crawlSingleUrl(item),
       new Promise((_, reject) => setTimeout(() => reject('timeout'), CRAWL_TIMEOUT_MS))
     ]);
   };
   ```

3. **모든 URL 한꺼번에 병렬 처리**
   ```typescript
   const crawlPromises = allUrlItems.map((item) => crawlWithTimeout(item));
   const results = await Promise.all(crawlPromises);
   ```

### 테스트 결과

| 단계 | 소요 시간 |
|------|----------|
| 1단계: URL 수집 (3개 포털 병렬) | 951ms |
| 2단계: 9개 URL 병렬 크롤링 | 5003ms |
| **전체** | **5954ms** |

### 성능 비교

| 측정 | 이전 (순차) | 현재 (병렬) | 개선율 |
|------|------------|------------|--------|
| all 검색 | 38.28초 | **5.95초** | **84%** |

### 원리

**이전 (순차)**:
```
naver(3초) → google(2초) → brave(30초) = 35초+
```

**현재 (병렬)**:
```
모든 URL 동시 시작 → max(개별 시간) = 5초 (타임아웃)
```

✅ 결론: **전체 병렬 크롤링 + 5초 타임아웃으로 38초 → 6초 (84% 단축)** 완료.

---

## 진행 결과 (2026-02-16, skip_content + LLM URL 선택)

### 문제
- 검색 결과 3개는 너무 적음 → 관련성 높은 정보 놓칠 수 있음
- 10개 전체를 크롤링하면 시간 낭비 (관련 없는 URL도 크롤링)

### 해결: 2단계 선택 구조

```
[기존]
검색(3개) → 전체 크롤링 → LLM 종합

[변경]
검색(10개, URL+snippet만) → LLM이 5개 선택 → 선택된 것만 크롤링 → 종합
         ↑                      ↑
    skip_content=true      더 에이전틱!
```

### 구현 내용

#### 1. smartCrawl 서버 (server.ts)

**새 추출 함수 추가**:
- `extractNaverResults(html, count, type)` - URL + title + snippet 추출
- `extractGoogleResults(html, count, type)` - URL + title + snippet 추출
- (Brave는 기존 `extractBraveResults` 사용)

**skip_content 파라미터 추가**:
```typescript
const { keyword, portal, count = 10, engine, type = 'news', skip_content = false } = req.body;

if (skip_content) {
  // Stage 2 (크롤링) 스킵 → URL+title+snippet만 반환
  const results = allUrlItems.map((item) => ({
    url: item.url,
    source: item.source,
    title: item.preExtracted?.title || '',
    snippet: item.preExtracted?.snippet || '',
  }));
  return res.json({ success: true, data: { results, skip_content: true }, ... });
}
```

#### 2. search_agent.py

**call_smartcrawl 수정**:
```python
async def call_smartcrawl(
    keyword: str,
    count: int = 10,           # 3 → 10으로 변경
    skip_content: bool = True,  # 기본: URL+snippet만
    ...
)
```

**SYSTEM_PROMPT 업데이트**:
```
## CRITICAL WORKFLOW:
1. Call search() to get 10+ URL+snippet results
2. Review snippets and SELECT the 5 most relevant URLs
3. Call fetch_url() with your selected 5 URLs to get full content
4. Generate final answer based on the fetched content
```

### API 사용법

```bash
# URL+snippet만 (크롤링 스킵) - 빠름
curl -X POST localhost:33003/search \
  -H 'Content-Type: application/json' \
  -d '{"keyword":"맥5 울트라","portal":"all","count":10,"skip_content":true}'

# 기존 방식 (전체 크롤링)
curl -X POST localhost:33003/search \
  -H 'Content-Type: application/json' \
  -d '{"keyword":"맥5 울트라","portal":"all","count":5,"skip_content":false}'
```

### E2E 테스트 결과

**테스트 쿼리**: "맥5 울트라 최신 정보"

| 단계 | 내용 | 시간 |
|------|------|------|
| Turn 1 | 검색 쿼리 생성 + 실행 (skip_content) | ~18초 |
| Turn 2 | LLM이 5개 URL 선택 + fetch_url | ~29초 |
| Turn 3 | 최종 답변 생성 | ~10초 |
| **총** | | **~58초** |

**LLM이 선택한 URL**:
- macworld.com (M5 Ultra 예상)
- macrumors.com (Mac Studio M5 Ultra 2026)
- techtimes.com (M5 Ultra 스펙/가격)
- 9to9trends.com (M5 Ultra 성능 점프)
- macrumors.com (Mac Studio 2026 루머)

**최종 답변 요약**:
- M5 Ultra Mac Studio 출시 예상: 2026년 중후반 (6월 또는 9월)
- 사양: 32 CPU 코어, 80 GPU 코어, 256GB+ 통합 메모리
- UltraFusion 기술 (M5 Max 2개 결합)
- 출처 5개 첨부

### 왜 더 에이전틱한가

| 항목 | 기존 | 변경 |
|------|------|------|
| LLM 역할 | 검색 쿼리만 계획 | 쿼리 계획 + **URL 선택** |
| 자율성 | 낮음 | 높음 |
| 효율성 | 모든 URL 크롤링 | 관련 URL만 크롤링 |

**에이전틱 핵심**: LLM이 스스로 계획 → 실행 → **선택** → 종합

✅ 결론: **skip_content + LLM URL 선택으로 에이전틱 자율성 확장** 완료.

---

## 진행 결과 (2026-02-16, SYSTEM_PROMPT 강화 - 5개 URL 병렬 fetch 강제)

### 문제
- LLM이 "5개 URL 선택" 지시를 따르지 않음
- **점진적 fetch**: 2개 먼저 → 실패하면 1개 추가 → 총 3개만 선택
- 설계 의도: 30개 수집 → **5개 선택 → 병렬 크롤링**

### 원인 분석

E2E 로그 확인 결과:
```
Turn 2: fetch_url(['economicnote.com', 'needinfo.co.kr'])  ← 2개만
Turn 3: fetch_url(['haul.kr'])  ← 1개 추가
→ 총 3개 (5개 아님)
```

**모델의 추론 패턴**:
- "먼저 2개 fetch해서 확인하고, 필요하면 더 가져오자" (점진적 접근)
- 이 전략은 합리적이지만 **설계 의도와 불일치**

### 해결: SYSTEM_PROMPT 명시적 강화

**수정 전**:
```
## CRITICAL WORKFLOW:
1. Call search() to get 10+ URL+snippet results
2. Review snippets and SELECT the 5 most relevant URLs
3. Call fetch_url() with your selected 5 URLs to get full content
4. Generate final answer based on the fetched content
```

**수정 후**:
```
## CRITICAL WORKFLOW (반드시 준수):
1. Call search() to get 10+ URL+snippet results
2. Review ALL snippets and SELECT EXACTLY 5 most relevant URLs
3. Call fetch_url() with ALL 5 URLs in a SINGLE call (NOT incrementally!)
   - ❌ WRONG: fetch 2 URLs first, then fetch more
   - ✅ CORRECT: fetch ALL 5 URLs at once in ONE call
4. Generate final answer based on the fetched content

⚠️ DO NOT use incremental fetching! Select 5 URLs upfront and fetch them all at once.
```

**fetch_url 도구 설명도 강화**:
```
2. fetch_url(url: list[str], purpose: str) - Fetch full webpage content.
   - MUST select EXACTLY 5 URLs and fetch them ALL in ONE call
   - DO NOT fetch incrementally (2 first, then more) - this wastes time!
```

### E2E 재검증 결과

**테스트 쿼리**: "삼성전자 주가예측"

| Turn | 동작 | 시간 |
|------|------|------|
| Turn 1 | 검색 쿼리 생성 (5개 쿼리, 3개만 실행) | 3.25초 + 16.63초 |
| Turn 2 | 추가 검색 (최신 정보 확인) | 9.84초 + 15.82초 |
| Turn 3 | **5개 URL 한 번에 fetch** | 15.21초 + 20.01초 |
| Turn 4 | 최종 답변 생성 | 26.68초 |

**Turn 3 fetch_url 호출**:
```
fetch_url({
  'url': [
    'https://www.gukjenews.com/...',
    'https://finance.thesmileinfo.com/...',
    'https://kr.investing.com/...',
    'https://wonforecast.com/...',
    'https://news.einfomax.co.kr/...'
  ],
  'purpose': '삼성전자 주가 예측 2026년 최신 정보 수집'
})
```

**병렬 fetch 결과**:
| URL | 시간 | 상태 |
|-----|------|------|
| kr.investing.com | 3.40초 | ✅ 성공 |
| finance.thesmileinfo.com | 4.39초 | ✅ 성공 |
| wonforecast.com | 7.58초 | ✅ 성공 |
| news.einfomax.co.kr | 10.52초 | ✅ 성공 |
| www.gukjenews.com | 20.01초 | ⏱️ 타임아웃 |

### 수정 전 vs 후

| 항목 | 수정 전 | 수정 후 |
|------|---------|---------|
| fetch 패턴 | 2개 → 1개 (점진적) | **5개 한 번에** |
| fetch 턴 수 | 2~3턴 | **1턴** |
| 총 fetch URL | 3개 | **5개** |
| 병렬화 효과 | 부분적 | **완전** |

### 핵심 교훈

1. **LLM은 명시적 지시가 필요** - "5개 선택"만으로는 부족
2. **잘못된 예시 제공이 효과적** - ❌ WRONG / ✅ CORRECT 패턴
3. **도구 설명에도 반복** - SYSTEM_PROMPT + 도구 description 양쪽에 명시

✅ 결론: **SYSTEM_PROMPT 강화로 5개 URL 병렬 fetch 강제** 완료.

---

## 진행 결과 (2026-02-16, 다양한 소스 10-15개 병렬 fetch)

### 문제
- 이전 "포털별 5개씩" 지시가 혼란 유발
- 검색 결과가 모두 "(brave)"로 태그되어 모델이 포털 구분 불가
- 모델이 snippet만으로 답변하고 fetch_url 생략

### 해결: SYSTEM_PROMPT 실용적 수정

**수정 전** (포털별 분리 - 혼란 유발):
```
1. Call search() to get 10+ results PER PORTAL (naver, google, brave)
2. From EACH portal's results, SELECT 5 most relevant URLs:
   - naver 10개 → 5개 선택
   - google 10개 → 5개 선택
   - brave 10개 → 5개 선택
3. Call fetch_url() with ALL 15 URLs in a SINGLE call
```

**수정 후** (실용적 - 다양한 소스):
```
## CRITICAL WORKFLOW (반드시 준수):
1. Call search() to get 30+ URL+snippet results (from naver, google, brave combined)
2. Review ALL snippets and SELECT 10-15 most relevant URLs from different sources
   - Pick diverse sources (different domains, different portals)
   - Prioritize recent articles (2026, 2025)
3. Call fetch_url() with ALL selected URLs in a SINGLE call
   - ❌ WRONG: answer from snippets without fetching
   - ❌ WRONG: fetch incrementally (2 first, then more)
   - ✅ CORRECT: fetch 10-15 URLs at once in ONE call
4. Generate final answer ONLY after fetching full content

⚠️ MUST fetch URLs before answering! Snippets alone are NOT enough!
```

**fetch_url 도구 설명도 수정**:
```
2. fetch_url(url: list[str], purpose: str) - Fetch full webpage content.
   - YOU MUST call this before generating final answer!
   - Select 10-15 diverse URLs and fetch ALL in ONE call
   - ❌ Never answer using only snippets - always fetch first!
```

### E2E 테스트 결과

**테스트 쿼리**: "삼성전자 주가예측"

| Turn | 동작 | 시간 |
|------|------|------|
| Turn 1 | 검색 (3개 쿼리) | 3.31초 + 16.51초 |
| Turn 2 | 분석 (도구 호출 없음) | 17.34초 |
| Turn 3 | **9개 URL 병렬 fetch** | 3.37초 + 20.01초 |
| Turn 4 | 타임아웃 URL 재시도 | 24.33초 + 0.97초 |
| Turn 5 | 최종 답변 생성 | 25.76초 |

**Turn 3 병렬 fetch (9개 URL)**:
| URL | 시간 | 상태 |
|-----|------|------|
| wonforecast.com | 1.25초 | ✅ |
| news.einfomax.co.kr | 1.94초 | ✅ |
| kr.tradingview.com | 4.55초 | ✅ |
| www.investchosun.com | 5.19초 | ✅ |
| m.finance.daum.net | 5.35초 | ✅ |
| comp.fnguide.com | 7.58초 | ✅ |
| chosun.com | 8.85초 | ✅ |
| alphasquare.co.kr | 9.24초 | ✅ |
| www.hankyung.com | 20.01초 | ⏱️ → 재시도 성공 |

### 개선 확인

| 항목 | 이전 | 현재 |
|------|------|------|
| fetch URL 수 | 5개 | **9개** |
| 소스 다양성 | 한정적 | **다양** (chosun, tradingview, fnguide, daum 등) |
| snippet만 답변 | 발생함 | **차단됨** (반드시 fetch 후 답변) |
| 최종 출처 수 | 5개 | **9개** |

### 핵심 변경점

1. **포털별 구분 제거** - 모델이 구분 못하므로 "다양한 소스"로 단순화
2. **fetch 필수 강조** - "❌ answer from snippets without fetching" 명시
3. **10-15개 권장** - 더 많은 정보 수집으로 답변 품질 향상

✅ 결론: **다양한 소스 10-15개 병렬 fetch + snippet 답변 차단** 완료.

---

## 진행 결과 (2026-02-16, 검색 최적화 + WebSearch 비교)

### 수정 내용

| 항목 | 변경 전 | 변경 후 |
|------|---------|---------|
| **쿼리 제한** | MAX_SEARCH_QUERIES = 3 | **5** |
| **전처리 사전** | Apple 제품만 | **NVIDIA GPU 추가** (블랙웰→Blackwell, 루빈→Rubin 등) |
| **검색 턴 제한** | 제한 없음 (4턴 발생) | **최대 2회** 후 fetch 강제 |
| **최소 URL** | 권장 10-15개 | **최소 10개 강제** |
| **max_tokens** | 2000 (응답 잘림) | **5000** |
| **힌트 포맷** | Python 리스트 | **쉼표 구분 문자열** |

### E2E 테스트 결과 (블랙웰 GPU 쿼리)

| Turn | 동작 | 시간 |
|------|------|------|
| Turn 1 | 검색 (3개 쿼리) | 3.11초 + 16.81초 |
| Turn 2 | **8개 URL 병렬 fetch** | 7.67초 + 19.58초 |
| Turn 3 | 최종 답변 생성 | 15.12초 |
| **총** | | **~90초** |

**전처리 작동 확인**:
```
[전처리] 외래어 감지: '블랙웰과 차세대 GPU' → ['Blackwell GPU', 'Blackwell GPU latest', 'Blackwell GPU 2026']
```

### WebSearch (Claude API) vs Agent Search 비교

| 항목 | Agent Search | WebSearch |
|------|--------------|-----------|
| **속도** | ~90초 | ~37초 |
| **출처 수** | 8개 | 10개 |
| **정보 초점** | Blackwell (현재) | Rubin (차세대) |
| **최신성** | 2026.02 기사 | CES 2026 발표 |
| **비용** | **무료** ⭐ | API 비용 |
| **오프라인** | **가능** ⭐ | 불가 |

### 핵심 발견

- **WebSearch**: "Vera Rubin" 차세대 플랫폼 정보 상세 (CES 2026 발표 기반)
- **Agent Search**: Blackwell 현재 제품에 집중, 기술 스펙 상세

✅ 결론: **검색 최적화 완료 (2회 제한 + 10개 URL + 전처리 강화)**

---

## 향후 해결 과제 (속도 문제점)

### 현재 병목 분석

| 단계 | 소요 시간 | 비율 | 병목 원인 |
|------|----------|------|----------|
| **검색 (smartCrawl)** | ~17초 | 19% | 크롤링 + 렌더링 |
| **fetch (Jina Reader)** | ~20초 | 22% | 외부 API 의존 |
| **모델 호출** | ~26초 | 29% | 4B 모델 추론 |
| **모델 thinking** | ~27초 | 30% | 긴 추론 체인 |
| **총** | **~90초** | 100% | |

### vs WebSearch (~37초)

| 항목 | Agent Search | WebSearch | 차이 |
|------|-------------|-----------|------|
| 속도 | 90초 | 37초 | **2.4배 느림** |
| 원인 | 크롤링+모델 | Anthropic 클라우드 검색 | 네트워크 지연 포함 |

> ⚠️ **측정 정정**: 이전 "~2초" 기록은 측정 오류. 실제 WebSearch도 ~37초 소요 (한국→미국 네트워크 지연 포함)

### 해결 방안 (우선순위)

#### 1. 검색 속도 개선 (높음)
- [ ] **Brave Search API** 직접 호출 (크롤링 제거)
- [ ] **Google Custom Search API** 활용
- [ ] 검색 결과 캐싱 (동일 쿼리 재사용)

#### 2. fetch 속도 개선 (높음)
- [ ] **로컬 크롤러** 구현 (Jina Reader 대체)
- [ ] **병렬 fetch 수 증가** (현재 15 → 30)
- [ ] 타임아웃 단축 (20초 → 10초)

#### 3. 모델 추론 개선 (중간)
- [ ] **더 큰 모델** 사용 (4B → 32B): 간결한 thinking
- [ ] **vLLM/SGLang** 최적화: 배치 처리
- [ ] **thinking 제한**: SYSTEM_PROMPT에 간결함 강조

#### 4. 아키텍처 개선 (낮음)
- [ ] **하이브리드 모드**: 빠른 답변은 WebSearch, 깊은 분석은 Agent Search
- [ ] **스트리밍 응답**: 검색 중 중간 결과 표시
- [ ] **비동기 파이프라인**: 검색/fetch/모델 병렬화

### 목표

| 항목 | 현재 | 목표 | 방법 |
|------|------|------|------|
| 총 시간 | 90초 | **30초** | API 검색 + 로컬 fetch |
| 검색 | 17초 | 3초 | Brave/Google API |
| fetch | 20초 | 10초 | 로컬 크롤러 + 타임아웃 단축 |
| 모델 | 53초 | 17초 | 32B 모델 + 간결한 thinking |

### 현실적 한계

- **WebSearch도 ~37초 소요**: Anthropic 클라우드 + 네트워크 지연 (한국→미국)
- **Agent Search와 차이 2.4배**: 90초 vs 37초 (이전 "45배" 기록은 측정 오류)
- **30초 목표 달성 가능**: API 검색 + 최적화로 WebSearch 수준 도달 가능
- **트레이드오프**: 속도 vs 비용 vs 오프라인 가용성

✅ 결론: **Agent Search 최적화로 WebSearch 수준 (~37초) 달성 가능**

---

## 상세 비교: Agent Search vs WebSearch (블랙웰 GPU 쿼리)

### 1. Agent Search (AgentCPM-Explore 4B + SmartCrawl)

| 항목 | 값 |
|------|-----|
| **총 시간** | ~90초 |
| **검색 턴** | 1회 (3개 쿼리) |
| **fetch URL** | 8개 (7개 성공, 1개 타임아웃) |
| **출처 수** | 8개 |
| **비용** | 무료 (로컬 모델) |

**주요 정보:**
- B200 GPU: 2080억 트랜지스터, 192GB HBM3e, 20 PFLOPS
- GB200 NVL72: 72개 GPU, 130TB/s
- 2026년 루빈, 2027년 루빈 Ultra 예정

---

### 2. WebSearch (Claude API)

| 항목 | 값 |
|------|-----|
| **총 시간** | ~37초 (이전 "~2초" 기록은 측정 오류) |
| **출처 수** | 10개 |
| **비용** | API 비용 |
| **실행 위치** | Anthropic 클라우드 (한국→미국 네트워크 지연 포함) |

**주요 정보:**
- **Vera Rubin 플랫폼**: CES 2026 발표, 6칩 플랫폼
- **성능**: Blackwell 대비 **5배 추론, 3.5배 학습**
- **Rubin GPU**: 50 PFLOPs 추론, HBM4 22TB/s (Blackwell 8TB/s 대비 2.75배)
- **용량**: 288GB (Blackwell 192GB 대비 1.5배)
- **출시**: 2026년 하반기

---

### 3. 비교 분석

| 항목 | Agent Search | WebSearch |
|------|--------------|-----------|
| **속도** | ~90초 | ~37초 (2.4배 빠름) |
| **출처 다양성** | 8개 | 10개 |
| **정보 초점** | Blackwell (현재) | Rubin (차세대) |
| **최신성** | 2026.02 기사 | CES 2026 발표 |
| **비용** | **무료** ⭐ | API 비용 |
| **오프라인** | **가능** ⭐ | 불가 |

---

### 4. 용도별 추천

| 용도 | 추천 |
|------|------|
| **속도 중요** | WebSearch (2.4배 빠름) |
| **비용 절감 / 오프라인** | Agent Search |
| **최신 정보** | WebSearch (CES 2026 포함) |
| **깊은 분석** | 둘 다 사용 (상호 보완) |

> ⚠️ **2026-02-16 측정 정정**: WebSearch 실제 측정 결과 ~37초 (이전 "~2초, 45배 빠름" 기록은 측정 오류)

**핵심 발견**: WebSearch는 "Vera Rubin" 차세대 플랫폼 정보를 더 상세히 제공 (CES 2026 발표 기반). Agent Search는 Blackwell 현재 제품에 집중.

---

**Sources (WebSearch):**
- [NVIDIA Rubin Platform Launch](https://nvidianews.nvidia.com/news/rubin-platform-ai-supercomputer)
- [Vera Rubin at CES 2026](https://finance.yahoo.com/news/nvidia-launches-vera-rubin-its-next-major-ai-platform-at-ces-2026-230045205.html)
- [Rubin 5X Performance](https://insideainews.com/2026/01/06/nvidia-releases-details-on-next-gen-vera-rubin-ai-platform-5x-the-performance-of-blackwell/)
- [Tom's Hardware Roadmap](https://www.tomshardware.com/pc-components/gpus/nvidia-announces-rubin-gpus-in-2026-rubin-ultra-in-2027-feynam-after)

---

## v1 vs v2 vs v3 비교 테스트 (2026-02-16)

### 테스트 조건

- **쿼리**: "삼성전자 주가 전망"
- **모델**: AgentCPM-Explore 4B (SGLang)
- **max_tokens**: v1/v2 5000, v3 5000 (2000→5000 수정 후)

### 성능 비교

| 항목 | v1 | v2 | v3 |
|------|-----|-----|-----|
| **실행 시간** | 85.35초 | 85.47초 | **79.89초** ⭐ |
| **완성도** | ✅ 완전 | ✅ 완전 | ✅ 완전 |
| **구조** | 5섹션+표 | 5섹션+표 | 7불릿 |
| **출처 수** | 8개 | 10개 | **15개** ⭐ |
| **출력 길이** | 62줄 | 83줄 | 26줄 |
| **표 포함** | ✅ | ✅ | ❌ |

### 정보 품질 비교

| 항목 | v1 | v2 | v3 |
|------|-----|-----|-----|
| **목표주가 범위** | 14.9~29만원 | 21~29만원 | 24~29만원 |
| **영업이익 예상** | 120~317조원 | 170~322조원 | 170조원 |
| **기술적 분석** | ❌ | ❌ | ✅ (차트분석) |
| **리스크 분석** | ✅ | ✅ | ✅ |

### 각 버전 특징

#### v1 (원본)
- **장점**: 속도·구조·품질 균형, 표로 목표주가 정리
- **단점**: 출처 수 적음 (8개)
- **출력**: `/tmp/agent_search_v1_run1.txt`

#### v2
- **장점**: 가장 상세한 내용 (83줄), 구조화 우수
- **단점**: 가장 느림 (85.47초)
- **출력**: `/tmp/agent_search_v2_run7.txt`

#### v3
- **장점**: 가장 빠름 (79.89초), 출처 많음 (15개), 차트 분석 포함
- **단점**: 표 없음, 간결한 불릿 형식
- **주의**: max_tokens 2000에서는 응답 끊김 발생 → 5000 필수
- **출력**: `/tmp/agent_search_v3_run18.txt`

### 용도별 추천

| 용도 | 추천 버전 |
|------|----------|
| **속도 중요** | v3 |
| **구조화/가독성** | v1, v2 |
| **출처 다양성** | v3 |
| **정보 밀도** | v2 |
| **균형 (기본)** | **v1** |

### 로그 파일

| 버전 | 로그 경로 |
|------|----------|
| v1 | `Agent_search/outputs/search_agent_logs/search_agent_log_20260216_223439.json` |
| v2 | `Agent_search_v2/outputs/search_agent_logs/search_agent_log_20260216_162403.json` |
| v3 | `Agent_search_v3/outputs/search_agent_logs/search_agent_log_20260216_223043.json` |

---

## max_tokens 비교 테스트 (2026-02-16)

### 테스트 조건

- **쿼리**: "삼성전자 주가 전망"
- **변수**: max_tokens (2000 / 5000 / 10000)
- **모델**: AgentCPM-Explore 4B (SGLang)

### max_tokens=10000 결과

| 항목 | v1 | v2 | v3 |
|------|-----|-----|-----|
| **시간** | 235.59초 | 124.63초 | **94.03초** ⭐ |
| **상태** | ❌ 오류 | ✅ 정상 | ✅ 정상 |
| **출력 길이** | 10줄 (오류) | 32줄 | **47줄** ⭐ |
| **출처 수** | 5개 | 10개 | **13개** ⭐ |

#### v1 오류 분석
- **출력**: "모델 호출 오류:"만 남음
- **시간**: 235초 (4분) - 과도한 thinking 후 타임아웃/OOM 추정
- **원인**: max_tokens=10000이 너무 커서 모델 과부하

#### v3 결과 (최고 품질)
- 7개 섹션: 실시간변동, 목표주가, 상승동력, 외국인, 기술분석, 리스크, 장기전망
- 목표주가: 14.9만원(평균) ~ 26만원(최고)
- 영업이익: 170~322조원
- **기술적 분석 포함**: 이동평균선, RSI, 지지/저항선

### v3 기준 max_tokens 비교

| max_tokens | 시간 | 상태 | 출력 길이 | 품질 |
|------------|------|------|----------|------|
| 2000 | 77초 | ❌ 끊김 | 35줄 | 불완전 |
| 5000 | 80초 | ✅ 정상 | 26줄 | 간결 |
| **10000** | **94초** | ✅ 정상 | **47줄** | **상세** ⭐ |

### max_tokens 권장값

| max_tokens | 평가 | 비고 |
|------------|------|------|
| 2000 | ❌ 비권장 | 응답 끊김 발생 |
| **5000** | ✅ **기본값 권장** | 안정성 + 속도 균형 |
| 10000 | ⚠️ 조건부 | v3만 안정, v1 오류 발생 |

### 결론

- **안정성 우선**: `max_tokens=5000` (모든 버전에서 안정)
- **품질 우선**: `max_tokens=10000` + v3 조합 (94초, 47줄, 13출처)
- **v1 주의**: max_tokens=10000에서 오류 발생 → 5000 이하 권장

### 출력 파일

| 버전 | max_tokens | 출력 파일 |
|------|------------|----------|
| v1 | 10000 | `/tmp/agent_search_v1_run2.txt` (오류) |
| v2 | 10000 | `/tmp/agent_search_v2_run8.txt` |
| v3 | 10000 | `/tmp/agent_search_v3_run19.txt` |

내용 품질                                                                                                    
                                                                                                               
  - 5개 섹션: 업체전망, 사업구조, 시장전망, 예상치요약, 종합평가                                               
  - 표 포함: 매출/영업이익/목표주가 정리                                                                       
  - 목표주가: 15.5~16만원 (하나증권, Nomura)                                                                   
  - 영업이익: 113조원 (+169%)                                                                                  
                                                                                                               
  ---                                                                                                          
  원인 확인                                                                                                    
                                                                                                               
  v1 오류 원인: 타임아웃 (120초 < 필요시간 ~150초)                                                             
  해결: MODEL_TIMEOUT = 180초                                                                                  
  ┌──────┬───────────────┬──────────────────────┐                                                              
  │ 버전 │ 기본 타임아웃 │   max_tokens=10000   │                                                              
  ├──────┼───────────────┼──────────────────────┤                                                              
  │ v1   │ 120초         │ ❌ 부족 → 180초 필요 │                                                              
  ├──────┼───────────────┼──────────────────────┤                                                              
  │ v2   │ ?             │ ✅ 충분              │                                                              
  ├──────┼───────────────┼──────────────────────┤                                                              
  │ v3   │ ?             │ ✅ 충분              │                                                              
  └──────┴───────────────┴──────────────────────┘                                                              
  ---                                                                                                          
  v1/v2/v3 최종 비교 (max_tokens=10000)                                                                        
  ┌───────────────┬────────────┬─────────┬───────────┐                                                         
  │     항목      │ v1 (180초) │   v2    │    v3     │                                                         
  ├───────────────┼────────────┼─────────┼───────────┤                                                         
  │ 시간          │ 156초      │ 124초   │ 85초 ⭐   │                                                         
  ├───────────────┼────────────┼─────────┼───────────┤                                                         
  │ 출력          │ 47줄       │ 64줄    │ 74줄 ⭐   │                                                         
  ├───────────────┼────────────┼─────────┼───────────┤                                                         
  │ 출처          │ 9개        │ 10개    │ 15개 ⭐   │                                                         
  ├───────────────┼────────────┼─────────┼───────────┤                                                         
  │ 표            │ 1개        │ 1개     │ 2개 ⭐    │                                                         
  ├───────────────┼────────────┼─────────┼───────────┤                                                         
  │ 목표주가 범위 │ 15.5~16만  │ 21~29만 │ 14.9~26만 │                                                         
  └───────────────┴────────────┴─────────┴───────────┘                                                         
  결론                                                                                                         
                                                                                                               
  v1 오류는 타임아웃 문제였습니다 (max_tokens 자체가 아님)                                                     
  ┌─────────────┬───────────────────┐                                                                          
  │    설정     │      권장값       │                                                                          
  ├─────────────┼───────────────────┤                                                                          
  │ max_tokens  │ 10000 (모든 버전) │                                                                          
  ├─────────────┼───────────────────┤                                                                          
  │ v1 타임아웃 │ 180초 (필수)      │
  └─────────────┴───────────────────┘

---

## v4 Depth 비교 테스트 (2026-02-17)

### 테스트 조건

- **쿼리**: "삼성전자 주가 전망"
- **모델**: AgentCPM-Explore 4B (SGLang)
- **max_tokens**: simple 3000, medium/deep 10000

### 성능 비교

| Depth | 시간 | 출력량 | 출처 수 | 상태 |
|-------|------|--------|---------|------|
| **simple** | 28.25초 | 34줄 | 6개 | ✅ 성공 |
| **medium** | 69.03초 | 42줄 | 14개 | ✅ 성공 |
| **deep** | 116.68초 | 77줄 | 20개 | ✅ 성공 |

### 각 Depth 특징

#### simple (빠른 개요)
- **시간**: ~30초
- **출력**: 가격 예측, 기대 요인, 기술적 지표, 리스크, 투자 전략
- **설정**: MAX_TURNS 3, max_tokens 3000
- **적합**: 빠른 브리핑, 간단한 확인

#### medium (균형)
- **시간**: ~70초
- **출력**: 4개 증권사 목표주가, 2026년 실적 전망, 주요 지원 요인
- **적합**: 일반적인 분석, 의사결정 지원

#### deep (심층 분석)
- **시간**: ~120초
- **출력**: 5개 증권사 + 표, 분기별 영업이익, 리스크 분석, 투자 포인트
- **적합**: 깊은 리서치, 상세 보고서

### v1~v4 전체 비교 (max_tokens=10000)

| 버전 | 시간 | 특징 |
|------|------|------|
| v1 | 156초 | 가장 느림, 안정적, 표 포함 |
| v2 | 124초 | 중간, 상세 구조화 |
| v3 | 85초 | 빠름, 출처 다양 |
| v4 deep | 117초 | depth 조절 가능 |
| **v4 medium** | **69초** | **빠르고 균형** ⭐ |
| **v4 simple** | **28초** | **최속** ⭐ |

### 용도별 추천

| 용도 | 추천 |
|------|------|
| 빠른 개요 | v4 simple (~30초) |
| 균형잡힌 분석 | v4 medium (~70초) |
| 심층 리서치 | v4 deep (~120초) |
| 최다 출처 | v3 (15개) |

### 출력 파일

| Depth | 출력 파일 |
|-------|----------|
| simple | `/tmp/agent_search_v4_simple_3.txt` |
| medium | `/tmp/agent_search_v4_medium.txt` |
| deep | `/tmp/agent_search_v4_deep.txt` |

### simple 오류 수정 이력

- **초기 문제**: "최대 턴 수 초과" 오류 (MAX_TURNS=2)
- **원인**: search → fetch 후 답변 생성 턴(3번째) 도달 전 종료
- **해결**: MAX_TURNS 3 이상 + max_tokens 3000으로 조정
- **결과**: 28.25초에 완전한 출력 생성                                                                          
                                                       